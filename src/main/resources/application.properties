# 服务器配置
server.port=7080

# lombok日志配置
logging.file.name=/Users/bjhl/Desktop/code/javacode/demo/log/test.log
logging.file.clean-history-on-start=false
logging.file.max-history=7
logging.file.max-size=10MB
logging.pattern.console=%d{yyyy/MM/dd-HH:mm:ss} %green([%thread]) %highlight(%-5level) %boldMagenta(%logger)- %cyan(%msg%n)
logging.pattern.file=%d{yyyy/MM/dd-HH:mm} %green([%thread]) %highlight(%-5level) %boldMagenta(%logger)- %cyan(%msg%n)

# 数据库配置
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/demo?characterEncoding=UTF-8&useSSL=false
spring.datasource.username=root
spring.datasource.password=MySQLKenan_07
# spring-data-jpa默认使用Hikari数据库连接池
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5

# Es配置
spring.data.elasticsearch.cluster-nodes=localhost:9300
spring.data.elasticsearch.cluster-name=elasticsearch

# Mvc配置
spring.mvc.view.suffix=.html
spring.mvc.static-path-pattern=/**
spring.resources.static-locations=classpath:/static/

# 日期格式化
spring.jackson.date-format=yyyy-MM-dd HH:mm:ss

# kafka配置
spring.kafka.consumer.bootstrap-servers=localhost:9092
# 自动提交时间间隔
spring.kafka.consumer.auto-commit-interval=1S
# 在偏移量无效的情况下，消费者从最新的记录开始读取数据(消费者启动之后生成的记录)
spring.kafka.consumer.auto-offset-reset=latest
# 为了避免出现重复数据和数据丢失，设置为false，然后手动提交偏移量
spring.kafka.consumer.enable-auto-commit=true
# 键/值的反序列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# group id
spring.kafka.consumer.group-id=test-group-id
# 发生错误，消息重发的次数
spring.kafka.producer.retries=0
# 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小
spring.kafka.producer.batch-size=16384
# 设置生产者内存缓冲区的大小
spring.kafka.producer.buffer-memory=33554432
# 键/值的序列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应
spring.kafka.producer.acks=1

